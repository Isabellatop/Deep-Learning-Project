{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Project_Final_part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69HiLwaj9iJl"
      },
      "source": [
        "## Improve the model by stacking multiple models into a larger model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYwRg8DRpol_",
        "outputId": "09d72e52-c57d-4f7b-f9f8-6a7edc23d3d3"
      },
      "source": [
        "# Install the OpenSlide C library and Python bindings\n",
        "# After installing these libraries, use `Runtime -> restart and run all` on the menu\n",
        "!apt-get install openslide-tools\n",
        "!pip install openslide-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libopenslide0\n",
            "Suggested packages:\n",
            "  libtiff-tools\n",
            "The following NEW packages will be installed:\n",
            "  libopenslide0 openslide-tools\n",
            "0 upgraded, 2 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 92.5 kB of archives.\n",
            "After this operation, 268 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenslide0 amd64 3.4.1+dfsg-2 [79.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 openslide-tools amd64 3.4.1+dfsg-2 [12.7 kB]\n",
            "Fetched 92.5 kB in 0s (222 kB/s)\n",
            "Selecting previously unselected package libopenslide0.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../libopenslide0_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Selecting previously unselected package openslide-tools.\n",
            "Preparing to unpack .../openslide-tools_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking openslide-tools (3.4.1+dfsg-2) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Setting up openslide-tools (3.4.1+dfsg-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting openslide-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/da/12dc0e7566ace61a5a65244220458dcb656b09cbf18ca50f3098875d97e4/openslide-python-1.1.2.tar.gz (316kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 17.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from openslide-python) (7.1.2)\n",
            "Building wheels for collected packages: openslide-python\n",
            "  Building wheel for openslide-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openslide-python: filename=openslide_python-1.1.2-cp37-cp37m-linux_x86_64.whl size=27648 sha256=69adffe0cff0dc550f0b8092d36756d84f15c74eb0b9d63ae77d92d8ed9c179f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/55/74/ba9d3dcc2c5c0f1282e08bae70df0ed57b496fb6b5c8f1adc9\n",
            "Successfully built openslide-python\n",
            "Installing collected packages: openslide-python\n",
            "Successfully installed openslide-python-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTTgSl70X413"
      },
      "source": [
        "%matplotlib inline\n",
        "import cv2\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkRfvJIrXz2I"
      },
      "source": [
        "# Read a region from the slide\n",
        "# Return a numpy RBG array\n",
        "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
        "    im = slide.read_region((x,y), level, (width, height))\n",
        "    im = im.convert('RGB') # drop the alpha channel\n",
        "    if as_float:\n",
        "        im = np.asarray(im, dtype=np.float32)\n",
        "    else:\n",
        "        im = np.asarray(im)\n",
        "    assert im.shape == (height, width, 3)\n",
        "    return im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u66yUDIiX4kg"
      },
      "source": [
        "#Find tissue \n",
        "def find_tissue_pixels(image, intensity=0.8):\n",
        "    im_gray = rgb2gray(image)\n",
        "    assert im_gray.shape == (image.shape[0], image.shape[1])\n",
        "    indices = np.where(im_gray <= intensity)\n",
        "    return list(zip(indices[0], indices[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dryoa1CX46Y"
      },
      "source": [
        "#Highlight tissue by coloring it red\n",
        "def apply_mask(im, mask, color=(255,0,0)):\n",
        "    masked = np.zeros((im.shape[0],im.shape[1],im.shape[2]))\n",
        "    for x,y in mask: masked[x][y] = color\n",
        "    return masked"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4vpEPqoY1QX"
      },
      "source": [
        "def preprocessing(slide_path,tumor_mask_path,patch_pixel,zoom_level):\n",
        "\n",
        "  #Create different folders with zoom level\n",
        "  zoom = str(zoom_level)\n",
        "  colab_root = '/content/'\n",
        "  tumor_f = os.path.join(colab_root,zoom+'_tumor/')\n",
        "  no_tumor_f = os.path.join(colab_root,zoom+'_no_tumor/')\n",
        "  tumor_mask_f = os.path.join(colab_root,zoom+'_tumor_mask/') \n",
        "  no_tumor_mask_f = os.path.join(colab_root,zoom+'_no_tumor_mask/') \n",
        "\n",
        "  if os.path.exists(tumor_f) or os.path.exists(no_tumor_f) or os.path.exists(no_tumor_mask_f) or os.path.exists(tumor_mask_f):\n",
        "    print(\"Some folders already exist\")\n",
        "  else:\n",
        "    os.mkdir(tumor_f)\n",
        "    os.mkdir(no_tumor_f)\n",
        "    os.mkdir(tumor_mask_f)\n",
        "    os.mkdir(no_tumor_mask_f) \n",
        "\n",
        "  #get image file name from specific slide path for future use\n",
        "  imagename = slide_path.split('.')[0].strip()\n",
        "\n",
        "  #open slide\n",
        "  slide = open_slide(slide_path)\n",
        "  tumor_mask = open_slide(tumor_mask_path)\n",
        "\n",
        "  #get slide's size\n",
        "  slide_width = slide.level_dimensions[zoom_level][0]\n",
        "  slide_height = slide.level_dimensions[zoom_level][1]\n",
        "  print('Slide path: '+ slide_path +' Slide Width:',slide_width, ' Slide height:', slide_height)\n",
        "\n",
        "  #read entire slide and mask at given zoom level\n",
        "  slide = read_slide(slide, x=0, y=0, level=zoom_level, width=slide_width,height=slide_height)\n",
        "  tumor_mask = read_slide(tumor_mask, x=0, y=0, level=zoom_level, width=slide_width,height=slide_height)\n",
        "\n",
        "  # Note: the program provided by the dataset authors generates a mask with R,G,B channels.\n",
        "  # The mask info we need is in the first channel only.\n",
        "  tumor_mask = tumor_mask[:,:,0]\n",
        "\n",
        "  # Improve efficiency by ignoring non-tissue areas of the slide.\n",
        "  # We'll find these by looking for all red regions.\n",
        "  tissue_pixels = find_tissue_pixels(slide)\n",
        "  tissue_regions = apply_mask(slide, tissue_pixels)\n",
        "\n",
        "  #Now we need to divide patches into corresponding folders\n",
        "  #First, given size of patch, get the number of patches\n",
        "  x,y = slide.shape[0], slide.shape[1]\n",
        "  num_xaxis, num_yaxis = int(np.ceil(x/patch_pixel)), int(np.ceil(y/patch_pixel))\n",
        "  print('Total number of pathches for this slide (including non-tissue region):', \n",
        "        int(num_xaxis*num_yaxis))\n",
        "\n",
        "  #Count tumor/ no tumor patch\n",
        "  count_t = 0\n",
        "  count_no_t = 0\n",
        "\n",
        "  #Go through every patch and find whether tumors exist\n",
        "  for i in range(num_xaxis):\n",
        "    for j in range(num_yaxis):\n",
        "      #Find patch's x,y corrdinates\n",
        "      #There are also some patches whose pixels < patch_pixel as we cannot divide slide evenly\n",
        "      if i == num_xaxis -1:\n",
        "        slide_x_end = x\n",
        "        patch_x_end = x-(num_xaxis-1)*patch_pixel\n",
        "      else:\n",
        "        slide_x_end = (i+1)*patch_pixel\n",
        "        patch_x_end = patch_pixel\n",
        " \n",
        "      if j == num_yaxis -1:\n",
        "        slide_y_end = y\n",
        "        patch_y_end = y-(num_yaxis-1)*patch_pixel\n",
        "      else:\n",
        "        slide_y_end = (j+1)*patch_pixel\n",
        "        patch_y_end = patch_pixel\n",
        "      \n",
        "      #Get patch and its mask from tissue region and check whether tissue exists\n",
        "      #If not exist, not save the patch and its mask\n",
        "      check_patch_tissue=np.zeros((patch_pixel,patch_pixel,3))\n",
        "      patch_img = np.zeros((patch_pixel,patch_pixel,3))\n",
        "      patch_mask_img = np.zeros((patch_pixel,patch_pixel))\n",
        "      \n",
        "      check_patch_tissue[0:patch_x_end,0:patch_y_end,:] = tissue_regions[i*patch_pixel:slide_x_end, j*patch_pixel:slide_y_end,:]\n",
        "\n",
        "      if np.mean(check_patch_tissue) > float(0): # there is tissue\n",
        "        #Get patch and its mask\n",
        "        patch_img[0:patch_x_end,0:patch_y_end,:]=slide[i*patch_pixel:slide_x_end, j*patch_pixel:slide_y_end,:]\n",
        "        patch_mask_img[0:patch_x_end,0:patch_y_end]=tumor_mask[i*patch_pixel:slide_x_end, j*patch_pixel:slide_y_end]\n",
        "\n",
        "        #Check wether there is tumor inside the patch through its mask image      \n",
        "        if np.mean(patch_mask_img)> float(0): #there is tumor\n",
        "          count_t+=1\n",
        "          patch_filename = tumor_f+str(imagename)+'_patch_'+str(i*num_yaxis+j)+'.jpg'\n",
        "          patch_mask_filename = tumor_mask_f+str(imagename)+'_patch_'+str(i*num_yaxis+j)+'.jpg'\n",
        "\n",
        "        else: #no tumor\n",
        "          count_no_t+=1\n",
        "          patch_filename = no_tumor_f+str(imagename)+'_patch_'+str(i*num_yaxis+j)+'.jpg'\n",
        "          patch_mask_filename = no_tumor_mask_f+str(imagename)+'_patch_'+str(i*num_yaxis+j)+'.jpg'  \n",
        "\n",
        "        #save patches with corresponding file name\n",
        "        cv2.imwrite(patch_filename,patch_img)  # put the patch img under the patch_filename path \n",
        "        cv2.imwrite(patch_mask_filename,patch_mask_img)  \n",
        "  print('Number of tumor patches:',count_t,' Number of no tumor patches:',count_no_t)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9TYliRG_FAI"
      },
      "source": [
        "### Load Data\n",
        "The slides we randomly chose are 'tumor_091', 'tumor_101' and 'tumor_110'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ43DJo8in1e"
      },
      "source": [
        "# Remove previously created files with zoom level 3\n",
        "\n",
        "!rm -rf tumor\n",
        "!rm -rf tumor_mask\n",
        "!rm -rf no_tumor\n",
        "!rm -rf no_tumor_mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHt2MZQIERk3",
        "outputId": "96c95452-15c7-43c4-c84c-ce5ec6c98861"
      },
      "source": [
        "# Download example slides and tumor masks\n",
        "\n",
        "slide_path1 = 'tumor_091.tif' \n",
        "tumor_mask_path1 = 'tumor_091_mask.tif' \n",
        "\n",
        "slide_url1 = 'https://storage.googleapis.com/applied-dl/%s' % slide_path1\n",
        "mask_url1 = 'https://storage.googleapis.com/applied-dl/%s' % tumor_mask_path1\n",
        "\n",
        "# Download the whole slide image\n",
        "if not os.path.exists(slide_path1):\n",
        "  !curl -O $slide_url1\n",
        "\n",
        "# Download the tumor mask\n",
        "if not os.path.exists(tumor_mask_path1):\n",
        "  !curl -O $mask_url1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  521M  100  521M    0     0   246M      0  0:00:02  0:00:02 --:--:--  246M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14.6M  100 14.6M    0     0  57.9M      0 --:--:-- --:--:-- --:--:-- 57.7M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZnEb_NUtqR8",
        "outputId": "51d0e11b-5503-4c5c-d199-ebab8bee18f9"
      },
      "source": [
        "# second slide\n",
        "slide_path2 = 'tumor_110.tif' \n",
        "tumor_mask_path2 = 'tumor_110_mask.tif' \n",
        "\n",
        "slide_url2 = 'https://storage.googleapis.com/adl_final4955/%s' % slide_path2\n",
        "mask_url2 = 'https://storage.googleapis.com/adl_final4955/%s' % tumor_mask_path2\n",
        "\n",
        "if not os.path.exists(slide_path2):\n",
        "  !curl -O $slide_url2\n",
        "\n",
        "if not os.path.exists(tumor_mask_path2):\n",
        "  !curl -O $mask_url2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1416M  100 1416M    0     0  86.6M      0  0:00:16  0:00:16 --:--:-- 61.1M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 31.3M  100 31.3M    0     0  32.6M      0 --:--:-- --:--:-- --:--:-- 32.6M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCxjt91vtrG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55edc00a-a674-4824-f8c3-f5ac1ae52882"
      },
      "source": [
        "# third slide\n",
        "slide_path3 = 'tumor_101.tif' \n",
        "tumor_mask_path3 = 'tumor_101_mask.tif' \n",
        "\n",
        "slide_url3 = 'https://storage.googleapis.com/adl_final4955/%s' % slide_path3\n",
        "mask_url3 = 'https://storage.googleapis.com/adl_final4955/%s' % tumor_mask_path3\n",
        "\n",
        "if not os.path.exists(slide_path3):\n",
        "  !curl -O $slide_url3\n",
        "\n",
        "if not os.path.exists(tumor_mask_path3):\n",
        "  !curl -O $mask_url3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1392M  100 1392M    0     0  37.5M      0  0:00:37  0:00:37 --:--:-- 46.5M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 43.9M  100 43.9M    0     0  37.8M      0  0:00:01  0:00:01 --:--:-- 37.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjBPak9SwkxF"
      },
      "source": [
        "In order to fit model well, we choose an patch size 299*299. \n",
        "\n",
        "Zoom Level 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N53eBg8MgyCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3acd0680-141a-4307-e6e4-41360dec9ed8"
      },
      "source": [
        "preprocessing(slide_path1,tumor_mask_path1,299,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slide path: tumor_091.tif Slide Width: 7680  Slide height: 6720\n",
            "Total number of pathches for this slide (including non-tissue region): 598\n",
            "Number of tumor patches: 27  Number of no tumor patches: 561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvBBAE8Mle09",
        "outputId": "baa77f7e-7c5c-4693-ee31-1ee7308f62d4"
      },
      "source": [
        "preprocessing(slide_path2,tumor_mask_path2,299,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some folders already exist\n",
            "Slide path: tumor_110.tif Slide Width: 11776  Slide height: 8960\n",
            "Total number of pathches for this slide (including non-tissue region): 1200\n",
            "Number of tumor patches: 275  Number of no tumor patches: 841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhSptY8mtiwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73548635-0cf1-4feb-a8a2-ab3d43af8229"
      },
      "source": [
        "preprocessing(slide_path3,tumor_mask_path3,299,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some folders already exist\n",
            "Slide path: tumor_101.tif Slide Width: 17408  Slide height: 8960\n",
            "Total number of pathches for this slide (including non-tissue region): 1770\n",
            "Number of tumor patches: 82  Number of no tumor patches: 1634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2dkKCwae02Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e674c04-7a82-468c-b43b-706aba69a300"
      },
      "source": [
        "no_tumor_f_len = len(os.listdir('/content/3_no_tumor'))\n",
        "tumor_f_len = len(os.listdir('/content/3_tumor'))\n",
        "print('Patch without tumor & zoom level 3:', no_tumor_f_len,' Patch with tumor & zoom level 3:',tumor_f_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Patch without tumor & zoom level 3: 3036  Patch with tumor & zoom level 3: 384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6xrtMMpeC9g"
      },
      "source": [
        "Zoom Level 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-1FsnhGhOAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1afe2d-cc7f-4150-e430-184e2df29344"
      },
      "source": [
        "preprocessing(slide_path1,tumor_mask_path1,299,4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slide path: tumor_091.tif Slide Width: 3840  Slide height: 3360\n",
            "Total number of pathches for this slide (including non-tissue region): 156\n",
            "Number of tumor patches: 12  Number of no tumor patches: 143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqv1oUqBeFrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46356f8-01ca-4c5f-acd1-ae9b5d98acac"
      },
      "source": [
        "preprocessing(slide_path2,tumor_mask_path2,299,4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some folders already exist\n",
            "Slide path: tumor_110.tif Slide Width: 5888  Slide height: 4480\n",
            "Total number of pathches for this slide (including non-tissue region): 300\n",
            "Number of tumor patches: 88  Number of no tumor patches: 191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sckb0FbZeM4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52994224-fd73-45d9-823a-9f8c6226f6a0"
      },
      "source": [
        "preprocessing(slide_path3,tumor_mask_path3,299,4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some folders already exist\n",
            "Slide path: tumor_101.tif Slide Width: 8704  Slide height: 4480\n",
            "Total number of pathches for this slide (including non-tissue region): 450\n",
            "Number of tumor patches: 40  Number of no tumor patches: 398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKgzUCOptdJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d266c32c-a816-436d-e9bb-d9b01573897d"
      },
      "source": [
        "no_tumor_f_len = len(os.listdir('/content/4_no_tumor'))\n",
        "tumor_f_len = len(os.listdir('/content/4_tumor'))\n",
        "print('Patch without tumor & zoom level 4:', no_tumor_f_len,' Patch with tumor & zoom level 4:',tumor_f_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Patch without tumor & zoom level 4: 732  Patch with tumor & zoom level 4: 140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJUjUStHfiI5"
      },
      "source": [
        "Zoom Level 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNubB5kTfkIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2bee01-ba54-45f2-9cb3-dc6266fe0d90"
      },
      "source": [
        "preprocessing(slide_path1,tumor_mask_path1,299,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slide path: tumor_091.tif Slide Width: 1920  Slide height: 1680\n",
            "Total number of pathches for this slide (including non-tissue region): 42\n",
            "Number of tumor patches: 6  Number of no tumor patches: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBvHv-mEfkZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60290058-0848-4fa5-8062-60728a106d01"
      },
      "source": [
        "preprocessing(slide_path2,tumor_mask_path2,299,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some folders already exist\n",
            "Slide path: tumor_110.tif Slide Width: 2944  Slide height: 2240\n",
            "Total number of pathches for this slide (including non-tissue region): 80\n",
            "Number of tumor patches: 34  Number of no tumor patches: 44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7vp1s-1fkqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3493d4da-4e1c-4cc3-e3e4-f0bb83f2fbc3"
      },
      "source": [
        "preprocessing(slide_path3,tumor_mask_path3,299,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some folders already exist\n",
            "Slide path: tumor_101.tif Slide Width: 4352  Slide height: 2240\n",
            "Total number of pathches for this slide (including non-tissue region): 120\n",
            "Number of tumor patches: 18  Number of no tumor patches: 101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwLTFV-pfk5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ccde88-3d77-4d85-8f40-4f7ee6f78d9f"
      },
      "source": [
        "no_tumor_f_len = len(os.listdir('/content/5_no_tumor'))\n",
        "tumor_f_len = len(os.listdir('/content/5_tumor'))\n",
        "print('Patch without tumor & zoom level 5:', no_tumor_f_len,' Patch with tumor & zoom level 5:',tumor_f_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Patch without tumor & zoom level 5: 181  Patch with tumor & zoom level 5: 58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBhuY0r-_tGP"
      },
      "source": [
        "### Create Training, Validation and Test Sets\n",
        "\n",
        "We can see the result above that the number of patches without tumor is quite larger than that of patches with tumor. This will result an very imbalanced dataset. Hence, we have decided to create a balanced dataset with all tumor patches we have and no tumor patches with similar size. Notice, the size of the dataset will not be large since we have a small number of tumor patches. This may have some impacts on validation accuracy later since we do not have much data to train.\n",
        "\n",
        "\n",
        "When creating training,validation and test sets, we follow a ratio of 4:1:1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQVjtFKO_z1s"
      },
      "source": [
        "#Create train, val and test directory\n",
        "#zoom level 3\n",
        "train_z3 = '/content/train_z3'\n",
        "val_z3 = '/content/val_z3'\n",
        "test_z3 = '/content/test_z3'\n",
        "\n",
        "os.mkdir(train_z3)\n",
        "os.mkdir(val_z3)\n",
        "os.mkdir(test_z3)\n",
        "\n",
        "train_tumor3 = os.path.join(train_z3,'tumor')\n",
        "train_no_tumor3 = os.path.join(train_z3,'no_tumor')\n",
        "os.mkdir(train_tumor3)\n",
        "os.mkdir(train_no_tumor3)\n",
        "\n",
        "val_tumor3 = os.path.join(val_z3,'tumor')\n",
        "val_no_tumor3 = os.path.join(val_z3,'no_tumor')\n",
        "os.mkdir(val_tumor3)\n",
        "os.mkdir(val_no_tumor3)\n",
        "\n",
        "test_tumor3 = os.path.join(test_z3,'tumor')\n",
        "test_no_tumor3 = os.path.join(test_z3,'no_tumor')\n",
        "os.mkdir(test_tumor3)\n",
        "os.mkdir(test_no_tumor3)\n",
        "\n",
        "#zoom level 4\n",
        "train_z4 = '/content/train_z4'\n",
        "val_z4 = '/content/val_z4'\n",
        "test_z4 = '/content/test_z4'\n",
        "\n",
        "os.mkdir(train_z4)\n",
        "os.mkdir(val_z4)\n",
        "os.mkdir(test_z4)\n",
        "\n",
        "train_tumor4 = os.path.join(train_z4,'tumor')\n",
        "train_no_tumor4 = os.path.join(train_z4,'no_tumor')\n",
        "os.mkdir(train_tumor4)\n",
        "os.mkdir(train_no_tumor4)\n",
        "\n",
        "val_tumor4 = os.path.join(val_z4,'tumor')\n",
        "val_no_tumor4 = os.path.join(val_z4,'no_tumor')\n",
        "os.mkdir(val_tumor4)\n",
        "os.mkdir(val_no_tumor4)\n",
        "\n",
        "test_tumor4 = os.path.join(test_z4,'tumor')\n",
        "test_no_tumor4 = os.path.join(test_z4,'no_tumor')\n",
        "os.mkdir(test_tumor4)\n",
        "os.mkdir(test_no_tumor4)\n",
        "\n",
        "#zoom level 5\n",
        "train_z5 = '/content/train_z5'\n",
        "val_z5 = '/content/val_z5'\n",
        "test_z5 = '/content/test_z5'\n",
        "\n",
        "os.mkdir(train_z5)\n",
        "os.mkdir(val_z5)\n",
        "os.mkdir(test_z5)\n",
        "\n",
        "train_tumor5 = os.path.join(train_z5,'tumor')\n",
        "train_no_tumor5 = os.path.join(train_z5,'no_tumor')\n",
        "os.mkdir(train_tumor5)\n",
        "os.mkdir(train_no_tumor5)\n",
        "\n",
        "val_tumor5 = os.path.join(val_z5,'tumor')\n",
        "val_no_tumor5 = os.path.join(val_z5,'no_tumor')\n",
        "os.mkdir(val_tumor5)\n",
        "os.mkdir(val_no_tumor5)\n",
        "\n",
        "test_tumor5 = os.path.join(test_z5,'tumor')\n",
        "test_no_tumor5 = os.path.join(test_z5,'no_tumor')\n",
        "os.mkdir(test_tumor5)\n",
        "os.mkdir(test_no_tumor5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhNUNyLF3v3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94de83ef-f301-434f-cb76-b6f681d30741"
      },
      "source": [
        "#shuffle tumor and no_tumor folders\n",
        "import random\n",
        "#zoom level 3\n",
        "tumor_img3 = os.listdir('/content/3_tumor')\n",
        "no_tumor_img3 = os.listdir('/content/3_no_tumor')\n",
        "random.shuffle(tumor_img3)\n",
        "random.shuffle(no_tumor_img3)\n",
        "tumor_len3 =len(tumor_img3)\n",
        "no_tumor_len3 = len(no_tumor_img3)\n",
        "print('Zoom level 3:')\n",
        "print('Tumor:',tumor_len3, ' No Tumor:', no_tumor_len3)\n",
        "\n",
        "#zoom level 4\n",
        "tumor_img4 = os.listdir('/content/4_tumor')\n",
        "no_tumor_img4 = os.listdir('/content/4_no_tumor')\n",
        "random.shuffle(tumor_img4)\n",
        "random.shuffle(no_tumor_img4)\n",
        "tumor_len4 =len(tumor_img4)\n",
        "no_tumor_len4 = len(no_tumor_img4)\n",
        "print('Zoom level 4:')\n",
        "print('Tumor:',tumor_len4, ' No Tumor:', no_tumor_len4)\n",
        "\n",
        "#zoom level 5\n",
        "tumor_img5 = os.listdir('/content/5_tumor')\n",
        "no_tumor_img5 = os.listdir('/content/5_no_tumor')\n",
        "random.shuffle(tumor_img5)\n",
        "random.shuffle(no_tumor_img5)\n",
        "tumor_len5 =len(tumor_img5)\n",
        "no_tumor_len5 = len(no_tumor_img5)\n",
        "print('Zoom level 5:')\n",
        "print('Tumor:',tumor_len5, ' No Tumor:', no_tumor_len5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zoom level 3:\n",
            "Tumor: 384  No Tumor: 3036\n",
            "Zoom level 4:\n",
            "Tumor: 140  No Tumor: 732\n",
            "Zoom level 5:\n",
            "Tumor: 58  No Tumor: 181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQcNgAFe8DH8"
      },
      "source": [
        "As we only have 384 patches with tumor, we will use 384 patches without tumor to keep balance. We divide those tumor patches and no-tumor pathces into training, validation and testing ratio of 4:1:1, and put them into respective folders. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3mrN44i43BD"
      },
      "source": [
        "import shutil\n",
        "#Zoom level 3\n",
        "#Training-Tumor\n",
        "for im in tumor_img3[0:int(tumor_len3*4/6)]:\n",
        "  shutil.copy(os.path.join('/content/3_tumor',im),train_tumor3)\n",
        "\n",
        "#Validation-Tumor\n",
        "for im in tumor_img3[int(tumor_len3*4/6):int(tumor_len3*5/6)]:\n",
        "  shutil.copy(os.path.join('/content/3_tumor',im),val_tumor3)\n",
        "\n",
        "# Test-Tumor\n",
        "for im in tumor_img3[int(tumor_len3*5/6):]:\n",
        "  shutil.copy(os.path.join('/content/3_tumor',im),test_tumor3)\n",
        "\n",
        "\n",
        "#Training-NoTumor\n",
        "for im in no_tumor_img3[0:int(tumor_len3*4/6)]:\n",
        "  shutil.copy(os.path.join('/content/3_no_tumor',im),train_no_tumor3)\n",
        "\n",
        "#Validation-NoTumor\n",
        "for im in no_tumor_img3[int(tumor_len3*4/6):int(tumor_len3*5/6)]:\n",
        "  shutil.copy(os.path.join('/content/3_no_tumor',im),val_no_tumor3)\n",
        "\n",
        "#Test-NoTumor\n",
        "for im in no_tumor_img3[int(tumor_len3*5/6):tumor_len3]:\n",
        "  shutil.copy(os.path.join('/content/3_no_tumor',im),test_no_tumor3)\n",
        "\n",
        "#Zoom level 4\n",
        "#Training-Tumor\n",
        "for im in tumor_img4[0:int(tumor_len4*4/6)]:\n",
        "  shutil.copy(os.path.join('/content/4_tumor',im),train_tumor4)\n",
        "\n",
        "#Validation-Tumor\n",
        "for im in tumor_img4[int(tumor_len4*4/6):int(tumor_len4*5/6)]:\n",
        "  shutil.copy(os.path.join('/content/4_tumor',im),val_tumor4)\n",
        "\n",
        "# Test-Tumor\n",
        "for im in tumor_img4[int(tumor_len4*5/6):]:\n",
        "  shutil.copy(os.path.join('/content/4_tumor',im),test_tumor4)\n",
        "\n",
        "\n",
        "#Training-NoTumor\n",
        "for im in no_tumor_img4[0:int(tumor_len4*4/6)]:\n",
        "  shutil.copy(os.path.join('/content/4_no_tumor',im),train_no_tumor4)\n",
        "\n",
        "#Validation-NoTumor\n",
        "for im in no_tumor_img4[int(tumor_len4*4/6):int(tumor_len4*5/6)]:\n",
        "  shutil.copy(os.path.join('/content/4_no_tumor',im),val_no_tumor4)\n",
        "\n",
        "#Test-NoTumor\n",
        "for im in no_tumor_img4[int(tumor_len4*5/6):tumor_len4]:\n",
        "  shutil.copy(os.path.join('/content/4_no_tumor',im),test_no_tumor4)\n",
        "\n",
        "\n",
        "#Zoom level 5\n",
        "#Training-Tumor\n",
        "for im in tumor_img5[0:int(tumor_len5*4/6)]:\n",
        "  shutil.copy(os.path.join('/content/5_tumor',im),train_tumor5)\n",
        "\n",
        "#Validation-Tumor\n",
        "for im in tumor_img5[int(tumor_len5*4/6):int(tumor_len5*5/6)]:\n",
        "  shutil.copy(os.path.join('/content/5_tumor',im),val_tumor5)\n",
        "\n",
        "# Test-Tumor\n",
        "for im in tumor_img5[int(tumor_len5*5/6):]:\n",
        "  shutil.copy(os.path.join('/content/5_tumor',im),test_tumor5)\n",
        "\n",
        "\n",
        "#Training-NoTumor\n",
        "for im in no_tumor_img5[0:int(tumor_len5*4/6)]:\n",
        "  shutil.copy(os.path.join('/content/5_no_tumor',im),train_no_tumor5)\n",
        "\n",
        "#Validation-NoTumor\n",
        "for im in no_tumor_img5[int(tumor_len5*4/6):int(tumor_len5*5/6)]:\n",
        "  shutil.copy(os.path.join('/content/5_no_tumor',im),val_no_tumor5)\n",
        "\n",
        "#Test-NoTumor\n",
        "for im in no_tumor_img5[int(tumor_len5*5/6):tumor_len5]:\n",
        "  shutil.copy(os.path.join('/content/5_no_tumor',im),test_no_tumor5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43XaCGWRnk06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddcc73fb-d5ee-46ac-f133-2e075f6a74c1"
      },
      "source": [
        "print(len(os.listdir('/content/train_z3/tumor')))\n",
        "print(len(os.listdir('/content/train_z3/no_tumor')))\n",
        "print(len(os.listdir('/content/train_z4/tumor')))\n",
        "print(len(os.listdir('/content/train_z4/no_tumor')))\n",
        "print(len(os.listdir('/content/train_z5/tumor')))\n",
        "print(len(os.listdir('/content/train_z5/no_tumor')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "256\n",
            "93\n",
            "93\n",
            "38\n",
            "38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s2Yuamcno2k"
      },
      "source": [
        "### Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnOPrXlUWqVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1b1340-04c4-4477-82f5-4d53faf20c7f"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator3 = train_datagen.flow_from_directory(\n",
        "        train_z3, # a path as string \n",
        "        target_size=(299,299), \n",
        "        class_mode='binary',\n",
        "        batch_size=32)\n",
        "\n",
        "for data_batch3, labels_batch3 in train_generator3:\n",
        "    print('data batch shape in zoom level 3:', data_batch3.shape)\n",
        "    print('labels batch shape in zoom level 3:', labels_batch3.shape)  \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 512 images belonging to 2 classes.\n",
            "data batch shape in zoom level 3: (32, 299, 299, 3)\n",
            "labels batch shape in zoom level 3: (32,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9bFfUs0V3ss"
      },
      "source": [
        "### Training Model\n",
        "#### Stacking three InceptionV3 models, each process images with a zoom  level of 3, 4 and 5 respectively. Then add a concatenating layer and a few layers on top. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmw44qWsV3IN"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "# First InceptionV3 model \n",
        "input_1 = Input(shape=(299, 299, 3))\n",
        "base_model_1 = Sequential()\n",
        "\n",
        "ince_1 = tf.keras.applications.InceptionV3(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(299,299, 3)\n",
        ")\n",
        "base_model_1.add(ince_1)\n",
        "base_model_1.trainable = False \n",
        "encoded_input_1 = base_model_1(input_1)\n",
        "\n",
        "# Second InceptionV3 model\n",
        "input_2 = Input(shape=(299, 299, 3))\n",
        "base_model_2 = Sequential()\n",
        "ince_2 = tf.keras.applications.InceptionV3(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(299,299, 3)\n",
        ")\n",
        "base_model_2.add(ince_2)\n",
        "base_model_2.trainable = False \n",
        "encoded_input_2 = base_model_2(input_2)\n",
        "\n",
        "# Third InceptionV3 model\n",
        "input_3 = Input(shape=(299, 299, 3))\n",
        "base_model_3 = Sequential()\n",
        "ince_3 = tf.keras.applications.InceptionV3(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(299,299, 3)\n",
        ")\n",
        "base_model_3.add(ince_3)\n",
        "base_model_3.trainable = False \n",
        "encoded_input_3 = base_model_3(input_3)\n",
        "\n",
        "# Let's concatenate 3 base models:\n",
        "merged = tf.keras.layers.concatenate([encoded_input_1,encoded_input_2,encoded_input_3])\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(merged)\n",
        "\n",
        "dense = tf.keras.layers.Dense(30, activation='relu')(global_average_layer)\n",
        "\n",
        "# Next, add a binary classifier on top\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "# This is our final model:\n",
        "final_model = Model(inputs=[input_1,input_2,input_3], outputs=output)\n",
        "\n",
        "\n",
        "final_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y_Gt6rjzRfD"
      },
      "source": [
        "# Create a function to read in intputs from 3 folders with different zoom levels  \n",
        "\n",
        "def multiple_generators(gen, X1, X2, X3):\n",
        "    genX1 = gen.flow_from_directory(directory = X1, target_size=(299,299), class_mode='binary',batch_size = 2)\n",
        "    genX2 = gen.flow_from_directory(directory = X2, target_size=(299,299), class_mode='binary',batch_size = 2)\n",
        "    genX3 = gen.flow_from_directory(directory = X3, target_size=(299,299), class_mode='binary',batch_size = 2)\n",
        "    while True:\n",
        "        X1i = genX1.next() # get the next batch\n",
        "        X2i = genX2.next()\n",
        "        X3i = genX3.next()\n",
        "        yield [X1i[0], X2i[0], X3i[0]], X1i[1] # [0] get batch's images, and [1] get labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyyS9EGy1F5u"
      },
      "source": [
        "train_multiple_generator = multiple_generators(train_datagen, train_z3, train_z4, train_z5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuBeIm_HUXCW",
        "outputId": "3678e445-699b-435c-d292-759acb6349e2"
      },
      "source": [
        "history = final_model.fit( \n",
        "      train_multiple_generator,\n",
        "      epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  65078/Unknown - 3686s 57ms/step - loss: 0.0081 - accuracy: 0.9975"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZuQwyi3wDPm"
      },
      "source": [
        "# train_generator3.next()[0].shape, len(train_generator3.next()[1]) # ((32, 299, 299, 3), 32)\n",
        "\n",
        "# len(validation_generator4.next()[1]) # 32"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}